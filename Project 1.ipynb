{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Scraping Amazon “Best Seller” Books Using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ipbnY7p.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction about Web Scraping\n",
    "\n",
    "Web scraping is an automatic method to obtain large amounts of data from websites. Most of this data is unstructured data in an HTML format which is then converted into structured data in a spreadsheet or a database so that it can be used in various applications. There are many different ways to perform web scraping to obtain data from websites. These include using online services, particular API’s or even creating your code for web scraping from scratch. Many large websites, like Google, Twitter, Facebook, StackOverflow, etc. have API’s that allow you to access their data in a structured format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/CHZJDr8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](blob:https://imgur.com/8f07cfd9-a916-4f11-bf51-73770e27232d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can we scrape data from everywhere?\n",
    "Before you get too deep into the process of scraping, bear in mind that scraping causes a spike in website traffic and may cause the website server to crash. As a result, not all websites enable scraping. So, how can you know which websites are permitted and which are prohibited? The website’s robots.txt ‘file can be examined. Simply add “/robots.txt” to the end of the URL you want to scrape to get information on whether the website’s host allows scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scrapping Libraries\n",
    "Data can be scraped in several ways. There are dozens of web-scraping libraries in Python as well, but some of the most notable are “Requests,” “Beautiful Soup,” “Scrapy,” “lxml,” “Selenium,” and “AWS Lambda.” Requests is a web scraping library that allows you to communicate with web servers; the rest relies on your use case, such as:\n",
    "\n",
    "1.Beautiful Soup: The Beautiful Soup library is an essential addition to your data science toolset since it is a basic and easy-to-use but powerful library that allows you to scrape data in just a few hours of practice. Its biggest strength is undoubtedly its simplicity.\n",
    "\n",
    "2.Scrapy: Scrapy is a Python-based open-source web scraping framework. It’s used to create a sophisticated web scraper. You’ll find all of the tools you need to extract data from websites, process it as needed, and store it in the structure and format you wish. \n",
    "\n",
    "3.Selenium: Complex and dynamic codes are present on websites. Furthermore, it is preferable to render all of the website content using a browser first. To reach the webpage, Selenium uses a genuine web browser. This gives the impression that a real person is accessing data in the same way.\n",
    "\n",
    "4.lxml: lxml is a production-quality HTML and XML parsing library with outstanding performance. You can rely on it to be beneficial to you regardless of which web page you are scraping.\n",
    "\n",
    "5.AWS Lambda: For simpler tasks, AWS Lambda is wonderful. It is integrated with all of Amazon’s services. A Docker container is used to run the scraper. Every day, AWS Cloud Watch event rules deploy scraping jobs to lambdas. You can operate the server on a schedule rather than manually starting and stopping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/ibrz0wS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping top selling books on amazon\n",
    "\n",
    "Amazon is one of the most popular online marketplaces used by both individual as well as businesses, and the site is available in many different countries and languages. Amazon Kindle is one of its most popular products as well as the Amazon app store. Lastly, Amazon offers software and infrastructure solutions for business and individuals.The page https://www.amazon.in/gp/bestsellers/books/ provides a list of top selling books Amazon. In this project,we'll retrive information from this page using _web scraping_ .\n",
    "We'll use the Python libraries [Requests](https://realpython.com/python-requests/) and [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) to scrape data from this page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's go to the [page](https://www.amazon.in/gp/bestsellers/books/) we want to scrape and take a look at its layout:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/8l3jLPq.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Outline:\n",
    "1. Download the webpage using 'requests'.\n",
    "2. Parse the HTML source code using BeautifulSoup\n",
    "3. Extract book name, author name, stars, price and url from page\n",
    "4. Compile extracted information into Python lists and dictionary\n",
    "5. Extract and combine data from multiple page\n",
    "6. Save the extracted information into a csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run the code\n",
    "You can execute the code using  the \"Run\" button at the top of this page and selecting `Run on Binder`\n",
    "\n",
    "Note:We will use the Jovian library and its commit() function throughout the code to save our progress as we move along"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jovian --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"mahadevaprashanthdm098/web-scraping-amazon-books\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/mahadevaprashanthdm098/web-scraping-amazon-books\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/mahadevaprashanthdm098/web-scraping-amazon-books'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute this to save new versions of the notebook\n",
    "jovian.commit(project=\"web-scraping-amazon-books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the web page using `requests`\n",
    "Requests library is one of the integral part of Python for making HTTP requests to a specified URL. Whether it be REST APIs or Web Scrapping, requests is must to be learned for proceeding further with these technologies. When one makes a request to a URI, it returns a response. Python requests provides inbuilt functionalities for managing both the request and response.The library can be installed using pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's install and import `Requests` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download a page we can use the `get` function from requests, which returns a response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "url= 'https://www.amazon.in/gp/bestsellers/books/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "response= requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check whether the web page is ordinary for web-scraping or not. If the status code falls between 200 and 299, the web page you selected is ordinary; otherwise, it is not. This status code refers to the status of a Hypertext Transfer Protocol (HTTP) response. A server issues status codes in response to a client’s request to the server. A complete list of user guides for these status codes can be found here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request was successful. We can get the contents of the pageusing `response.text`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_contents= response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328636"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(page_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The web page contains the HTML code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!doctype html><html lang=\"en-in\" class=\"a-no-js\" data-19ax5a9jf=\"dingo\"><!-- sp:feature:head-start -->\\n<head><script>var aPageStart = (new Date()).getTime();</script><meta charset=\"utf-8\"/>\\n<!-- sp:end-feature:head-start -->\\n<!-- sp:feature:csm:head-open-part1 -->\\n\\n<!-- sp:end-feature:csm:head-open-part1 -->\\n<!-- sp:feature:cs-optimization -->\\n<meta http-equiv=\\'x-dns-prefetch-control\\' content=\\'on\\'>\\n<link rel=\"dns-prefetch\" href=\"https://images-eu.ssl-images-amazon.com\">\\n<link rel=\"dns-prefetch\" href=\"https://m.media-amazon.com\">\\n<link rel=\"dns-prefetch\" href=\"https://completion.amazon.com\">\\n<!-- sp:end-feature:cs-optimization -->\\n<!-- sp:feature:csm:head-open-part2 -->\\n\\n<!-- sp:end-feature:csm:head-open-part2 -->\\n<!-- sp:feature:aui-assets -->\\n<link rel=\"stylesheet\" href=\"https://images-eu.ssl-images-amazon.com/images/I/11EIQ5IGqaL._RC|01ZTHTZObnL.css,41C-I1lXVwL.css,31ufSReDtSL.css,013z33uKh2L.css,017DsKjNQJL.css,0131vqwP5UL.css,41EWOOlBJ9L.css,11TIuySqr6L.css,01ElnPiDxWL.css,11Qjwq-'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_contents[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we are looking at above is the [HTML source code]()of the web page.\n",
    "\n",
    "We can also save it to a file and view the page locally within Jupyter using \"File > Open\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully download the web page using request."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Use Beautiful Soup to parse and extract information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is BeautifulSoup?\n",
    "Beautiful Soup is a Python library for pulling data out of HTML and XML files. It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree. It commonly saves programmers hours or days of work.For more details go through this link \n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's install and import `BeautifulSoup` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the library\n",
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc=BeautifulSoup(page_contents, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can use the `Beautiful Soup` class to parse the HTML document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is going to parse the webpage using requests and beautifulsoup\n",
    "def get_page(url):\n",
    "    print(\"Scraping URL:\", url)\n",
    "    response= requests.get(url)\n",
    "    print (\"Status code:\",response.status_code)\n",
    "    page_contents= response.text\n",
    "    with open('webpage.html', 'w') as f:\n",
    "        f.write(response.text)\n",
    "    doc = BeautifulSoup(page_contents, 'html.parser')\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://i.imgur.com/nH2A7kj.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extracting Book Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting title of the book\n",
    "book_title_tags= doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_title_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"a-link-normal\" href=\"/Starts-Us-Colleen-Hoover/dp/1398518174/ref=zg_bs_books_sccl_1/000-0000000-0000000?pd_rd_i=1398518174&amp;psc=1\" role=\"link\" tabindex=\"-1\"><div class=\"a-section a-spacing-mini _cDEzb_noop_3Xbw5\"><img alt=\"It Starts With Us\" class=\"a-dynamic-image p13n-sc-dynamic-image p13n-product-image\" data-a-dynamic-image='{\"https://images-eu.ssl-images-amazon.com/images/I/81FummIc2eL._AC_UL300_SR300,200_.jpg\":[300,200],\"https://images-eu.ssl-images-amazon.com/images/I/81FummIc2eL._AC_UL600_SR600,400_.jpg\":[600,400],\"https://images-eu.ssl-images-amazon.com/images/I/81FummIc2eL._AC_UL900_SR900,600_.jpg\":[900,600]}' height=\"200px\" src=\"https://images-eu.ssl-images-amazon.com/images/I/81FummIc2eL._AC_UL300_SR300,200_.jpg\" style=\"max-width:300px;max-height:200px\"/></div></a>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_title_tags[0].find('a',{'class':'a-link-normal'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It Starts With Us'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# title of the first book\n",
    "book_title_tags[0].find('span').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_title(doc):\n",
    "    book_title_tags= doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})\n",
    "    Book_Titles=[]\n",
    "    for tag in book_title_tags:\n",
    "        try:\n",
    "            title_tag = tag.find('span')\n",
    "            Book_Titles.append(title_tag.text)\n",
    "        except :\n",
    "            Book_Titles.append(\"Not Available\")\n",
    "    return Book_Titles\n",
    "# this function will give the titles of the books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It Starts With Us',\n",
       " 'War of Lanka (Ram Chandra Series Book 4)',\n",
       " 'Atomic Habits: The life-changing million copy bestseller',\n",
       " 'Ikigai: The Japanese secret to a long and happy life',\n",
       " 'The Psychology of Money',\n",
       " 'It Ends With Us: A Novel: Volume 1',\n",
       " 'The Power of Your Subconscious Mind',\n",
       " 'The Hidden Hindu',\n",
       " 'Trading Chart Breakout Pattern & Candlestick Pattern Pocket Study For Beginners',\n",
       " 'My First Library: Boxset of 10 Board Books for Kids']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_book_title(doc)[:10]       # titles of top ten  selling books on amazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " we have successfully scraped the title of the books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extracting Author Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting Author name by defining tag and class in html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_name_tags= doc.find_all('div',{'class':'zg-grid-general-faceout'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(author_name_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"a-size-small a-link-child\" href=\"/Colleen-Hoover/e/B006SKAK42/ref=zg_bs_books_bl_sccl_1/000-0000000-0000000?pd_rd_i=1398518174\"><div class=\"_cDEzb_p13n-sc-css-line-clamp-1_1Fn1y\">Colleen Hoover</div></a>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_name_tags[0].find('a',{'class':'a-size-small a-link-child'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_authors(doc):\n",
    "    author_name_tags= doc.find_all('div',{'class':'zg-grid-general-faceout'})\n",
    "    Author_Names=[]\n",
    "    for tag in author_name_tags:\n",
    "        try:\n",
    "            Author_Names.append(tag.find('div',{'class':'a-row a-size-small'}).text)\n",
    "        except :\n",
    "            Author_Names.append(\"Not Available\")\n",
    "    return Author_Names\n",
    "# This function will help to get the name of the authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Colleen Hoover',\n",
       " 'Amish Tripathi',\n",
       " 'James Clear',\n",
       " 'Héctor García',\n",
       " 'Morgan Housel',\n",
       " 'Colleen Hoover',\n",
       " 'Joseph Murphy',\n",
       " 'Akshat Gupta',\n",
       " 'Akash Kundur',\n",
       " 'Wonder House Books']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_authors(doc)[:10] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  3. Extracting  star rating on each book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating= 'a-icon a-icon-star-small a-star-small-4-5 aok-align-top'\n",
    "rating_tags= doc.find_all('i',{'class': rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_stars(doc):\n",
    "    rating_tags= doc.find_all('div',{'class':'zg-grid-general-faceout'})\n",
    "    Stars=[]\n",
    "    for tag in rating_tags:\n",
    "        try:\n",
    "            Stars.append(tag.find('span',{'class':'a-icon-alt'}).text)\n",
    "        except :\n",
    "            Stars.append(\"Not Available\")\n",
    "            \n",
    "    return Stars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rating = rating_tags[0].find('i',{'class':rating})\n",
    "if title:\n",
    "    title_list.append(title)\n",
    "else:\n",
    "    append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.6 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.7 out of 5 stars',\n",
       " '4.6 out of 5 stars',\n",
       " '4.6 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.5 out of 5 stars',\n",
       " '4.4 out of 5 stars',\n",
       " '4.1 out of 5 stars',\n",
       " '4.5 out of 5 stars']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_all_stars(doc)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extracting Book Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_price_tags= doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_price_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_price(doc):\n",
    "    book_price_tags= doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})\n",
    "    Book_Price=[]\n",
    "    for tag in book_price_tags:\n",
    "        try:\n",
    "            Book_Price.append(tag.find('span',{'class':'p13n-sc-price'}).text)\n",
    "        except :\n",
    "            Book_Price.append(\"Not Available\")\n",
    "            \n",
    "    return Book_Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['₹185.00',\n",
       " '₹314.00',\n",
       " '₹414.00',\n",
       " '₹257.00',\n",
       " '₹230.00',\n",
       " '₹225.00',\n",
       " '₹99.00',\n",
       " '₹141.00',\n",
       " '₹199.00',\n",
       " '₹399.00']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " get_all_price(doc)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have scraped the price of top 10 selling books on amazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Extracting  Book URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "book_url_tag=doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(book_url_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_url(doc):\n",
    "    book_url_tag=doc.find_all('div',{\"class\": \"zg-grid-general-faceout\"})\n",
    "    Book_Title_Urls=[]\n",
    "    base_url=\"https://www.amazon.in\"\n",
    "    for tag in book_url_tag:\n",
    "        try:\n",
    "            Book_Title_Urls.append(base_url + tag.find('a',{'class':'a-link-normal'})['href'])\n",
    "        except :\n",
    "            Book_Title_Urls.append(\"Not Available\")\n",
    "    return Book_Title_Urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.amazon.in/Starts-Us-Colleen-Hoover/dp/1398518174/ref=zg_bs_books_sccl_1/000-0000000-0000000?pd_rd_i=1398518174&psc=1',\n",
       " 'https://www.amazon.in/War-Lanka-Ram-Chandra-Book/dp/9356291527/ref=zg_bs_books_sccl_2/000-0000000-0000000?pd_rd_i=9356291527&psc=1',\n",
       " 'https://www.amazon.in/Atomic-Habits-James-Clear/dp/1847941834/ref=zg_bs_books_sccl_3/000-0000000-0000000?pd_rd_i=1847941834&psc=1',\n",
       " 'https://www.amazon.in/Ikigai-H%C3%A9ctor-Garc%C3%ADa/dp/178633089X/ref=zg_bs_books_sccl_4/000-0000000-0000000?pd_rd_i=178633089X&psc=1',\n",
       " 'https://www.amazon.in/Psychology-Money-Morgan-Housel/dp/9390166268/ref=zg_bs_books_sccl_5/000-0000000-0000000?pd_rd_i=9390166268&psc=1',\n",
       " 'https://www.amazon.in/Ends-Us-Novel-Colleen-Hoover/dp/1501110365/ref=zg_bs_books_sccl_6/000-0000000-0000000?pd_rd_i=1501110365&psc=1',\n",
       " 'https://www.amazon.in/Power-Your-Subconscious-Mind/dp/8194790832/ref=zg_bs_books_sccl_7/000-0000000-0000000?pd_rd_i=8194790832&psc=1',\n",
       " 'https://www.amazon.in/Hidden-Hindu-Akshat-Gupta/dp/0143455699/ref=zg_bs_books_sccl_8/000-0000000-0000000?pd_rd_i=0143455699&psc=1',\n",
       " 'https://www.amazon.in/Trading-Breakout-Pattern-Candlestick-Beginners/dp/B09Z85R4SW/ref=zg_bs_books_sccl_9/000-0000000-0000000?pd_rd_i=B09Z85R4SW&psc=1',\n",
       " 'https://www.amazon.in/My-First-Library-Boxset-Board/dp/9387779262/ref=zg_bs_books_sccl_10/000-0000000-0000000?pd_rd_i=9387779262&psc=1']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_url(doc)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successful scraped 10 book url."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract and combine data from multiple pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to get the BS4 doc by providing the page number\n",
    "def get_doc(page_number):\n",
    "    url='https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_{}?ie=UTF8&pg={}'.format(str(page_number),str(page_number)) \n",
    "    doc=get_page(url)\n",
    "    return doc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a DataFrame using `Pandas`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Pandas?\n",
    "Pandas is an open-source library that is made mainly for working with relational or labeled data both easily and intuitively. It provides various data structures and operations for manipulating numerical data and time series. This library is built on top of the NumPy library. Pandas is fast and it has high performance & productivity for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Data Frame?\n",
    "A DataFrame is a data structure that organizes data into a 2-dimensional table of rows and columns, much like a spreadsheet. DataFrames are one of the most common data structures used in modern data analytics because they are a flexible and intuitive way of storing and working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The import pandas portion of the code tells Python to bring the pandas data analysis library into your current environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At last extract all the details from a page\n",
    "import time\n",
    "def get_all_details(n):\n",
    "    all_books={'Title': [], 'Author': [], 'Stars': [], 'Price': [], 'URL': []}\n",
    "    for page_number in range(1,n+1):\n",
    "        doc = get_doc(page_number)\n",
    "        all_books['Title'] += get_book_title(doc)\n",
    "        all_books['Author'] += get_all_authors(doc)\n",
    "        all_books['Stars'] += get_all_stars(doc)\n",
    "        all_books['Price'] += get_all_price(doc)\n",
    "        all_books['URL'] += get_all_url(doc)\n",
    "    return all_books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame is a 2-dimensional array. The following code shows how to quickly create a DataFrame using pandas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "book_box = doc.find_all('div', class_=\"p13n-asin-index-0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "title = book_box[0].find(tag_for_title, class_fortitle)\n",
    "if title:\n",
    "    title_list.append(title)\n",
    "else:\n",
    "    append(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping URL: https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_1?ie=UTF8&pg=1\n",
      "Status code: 200\n",
      "Scraping URL: https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_2?ie=UTF8&pg=2\n",
      "Status code: 200\n",
      "Scraping URL: https://www.amazon.in/gp/bestsellers/books/ref=zg_bs_pg_3?ie=UTF8&pg=3\n",
      "Status code: 200\n"
     ]
    }
   ],
   "source": [
    "dataframe = pd.DataFrame.from_dict(get_all_details(3), orient= 'index')\n",
    "dataframe= dataframe.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Stars</th>\n",
       "      <th>Price</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It Starts With Us</td>\n",
       "      <td>Colleen Hoover</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹185.00</td>\n",
       "      <td>https://www.amazon.in/Starts-Us-Colleen-Hoover...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>War of Lanka (Ram Chandra Series Book 4)</td>\n",
       "      <td>Amish Tripathi</td>\n",
       "      <td>4.1 out of 5 stars</td>\n",
       "      <td>₹314.00</td>\n",
       "      <td>https://www.amazon.in/War-Lanka-Ram-Chandra-Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Atomic Habits: The life-changing million copy ...</td>\n",
       "      <td>James Clear</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>₹414.00</td>\n",
       "      <td>https://www.amazon.in/Atomic-Habits-James-Clea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ikigai: The Japanese secret to a long and happ...</td>\n",
       "      <td>Héctor García</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹257.00</td>\n",
       "      <td>https://www.amazon.in/Ikigai-H%C3%A9ctor-Garc%...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Psychology of Money</td>\n",
       "      <td>Morgan Housel</td>\n",
       "      <td>4.6 out of 5 stars</td>\n",
       "      <td>₹230.00</td>\n",
       "      <td>https://www.amazon.in/Psychology-Money-Morgan-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>UGC NET /SET/JRF Paper 1 Teaching and Research...</td>\n",
       "      <td>KVS Madaan</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹287.00</td>\n",
       "      <td>https://www.amazon.in/UGC-Paper-Teaching-Resea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Errorless 45 Previous Years IIT JEE Advanced (...</td>\n",
       "      <td>Disha Experts</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "      <td>₹1,659.00</td>\n",
       "      <td>https://www.amazon.in/Errorless-Previous-Years...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>101 Tales The Great Panchatantra Collection - ...</td>\n",
       "      <td>Wonder House Books</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>₹292.00</td>\n",
       "      <td>https://www.amazon.in/101-Tales-Great-Panchata...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>1984</td>\n",
       "      <td>George Orwell</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>₹79.00</td>\n",
       "      <td>https://www.amazon.in/1984-George-Orwell/dp/93...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>OXFORD ENGLISH MINI DICTIONARY 7TH EDITION</td>\n",
       "      <td>Dictionaries</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>₹143.30</td>\n",
       "      <td>https://www.amazon.in/Oxford-English-Mini-Dict...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title              Author  \\\n",
       "0                                    It Starts With Us      Colleen Hoover   \n",
       "1             War of Lanka (Ram Chandra Series Book 4)      Amish Tripathi   \n",
       "2    Atomic Habits: The life-changing million copy ...         James Clear   \n",
       "3    Ikigai: The Japanese secret to a long and happ...       Héctor García   \n",
       "4                              The Psychology of Money       Morgan Housel   \n",
       "..                                                 ...                 ...   \n",
       "145  UGC NET /SET/JRF Paper 1 Teaching and Research...          KVS Madaan   \n",
       "146  Errorless 45 Previous Years IIT JEE Advanced (...       Disha Experts   \n",
       "147  101 Tales The Great Panchatantra Collection - ...  Wonder House Books   \n",
       "148                                               1984       George Orwell   \n",
       "149         OXFORD ENGLISH MINI DICTIONARY 7TH EDITION        Dictionaries   \n",
       "\n",
       "                  Stars      Price  \\\n",
       "0    4.6 out of 5 stars    ₹185.00   \n",
       "1    4.1 out of 5 stars    ₹314.00   \n",
       "2    4.7 out of 5 stars    ₹414.00   \n",
       "3    4.6 out of 5 stars    ₹257.00   \n",
       "4    4.6 out of 5 stars    ₹230.00   \n",
       "..                  ...        ...   \n",
       "145  4.4 out of 5 stars    ₹287.00   \n",
       "146  4.0 out of 5 stars  ₹1,659.00   \n",
       "147  4.5 out of 5 stars    ₹292.00   \n",
       "148  4.5 out of 5 stars     ₹79.00   \n",
       "149  4.4 out of 5 stars    ₹143.30   \n",
       "\n",
       "                                                   URL  \n",
       "0    https://www.amazon.in/Starts-Us-Colleen-Hoover...  \n",
       "1    https://www.amazon.in/War-Lanka-Ram-Chandra-Bo...  \n",
       "2    https://www.amazon.in/Atomic-Habits-James-Clea...  \n",
       "3    https://www.amazon.in/Ikigai-H%C3%A9ctor-Garc%...  \n",
       "4    https://www.amazon.in/Psychology-Money-Morgan-...  \n",
       "..                                                 ...  \n",
       "145  https://www.amazon.in/UGC-Paper-Teaching-Resea...  \n",
       "146  https://www.amazon.in/Errorless-Previous-Years...  \n",
       "147  https://www.amazon.in/101-Tales-Great-Panchata...  \n",
       "148  https://www.amazon.in/1984-George-Orwell/dp/93...  \n",
       "149  https://www.amazon.in/Oxford-English-Mini-Dict...  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Create CSV file(s) with the extracted information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv('books.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have successfully scraped all the important information as per requirement from a website and combined the data into a \n",
    "CSV file.\n",
    "\n",
    "- First, we installed all of the necessary libraries in our Jupyter notebook.\n",
    "- Using the requests library, we download the web page to our notebook.\n",
    "- We inspect the web page for HTML tags for all required attributes regarding each data that we want to scrape from the web page.\n",
    "- The data from each HTML tag is then collected and written into a Python dictionary.\n",
    "- For collecting the data from different pages we have written some helper functions and then we have written a parser function to extract all the data from each different page and then parse the collected data into a python dictionary.\n",
    "- We constructed various helper methods(functions) to gather data from various pages, and then we write a parser function to extract all of the data from each page, and then we parse the collected data into a Python dictionary.\n",
    "- Finally, we have created a CSV file using the panda’s library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can work forward in this project and extract many meaningful information in upcoming time.\n",
    "We can analyze this data and give many useful answers like-\n",
    "- Which book has high Sales Rank?\n",
    "- Which book has lowest customer's review?\n",
    "- Which book has highest rating?\n",
    "- Which book has lowest price but high rating?\n",
    "- Which book has lowest rating?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "[1] Aakash N S, Introduction to Web Scraping, 2021. https://jovian.ai/aakashns/python-web-scraping-and-rest-api\n",
    "\n",
    "[2] Working with Jupyter Notebook https://towardsdatascience.com/write-markdown-latex-in-the-jupyter-notebook-10985edb91fd\n",
    "\n",
    "[3] Python offical documentation. https://docs.python.org/3/\n",
    "\n",
    "[4] Requests library. https://pypi.org/project/requests/\n",
    "\n",
    "[5] Beautiful Soup documentation. https://www.crummy.com/software/BeautifulSoup/bs4/doc/\n",
    "\n",
    "[6] Pandas library documentation. https://pandas.pydata.org/docs/\n",
    "\n",
    "[7] Web Scraping Article. https://www.toptal.com/python/web-scraping-with-python\n",
    "\n",
    "[8] Web Scraping Image. https://morioh.com/p/431153538ecb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jovian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "window.require && require([\"base/js/namespace\"],function(Jupyter){Jupyter.notebook.save_checkpoint()})"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[jovian] Updating notebook \"mahadevaprashanthdm098/web-scraping-amazon-books\" on https://jovian.ai\u001b[0m\n",
      "[jovian] Uploading additional files...\u001b[0m\n",
      "[jovian] Committed successfully! https://jovian.ai/mahadevaprashanthdm098/web-scraping-amazon-books\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://jovian.ai/mahadevaprashanthdm098/web-scraping-amazon-books'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jovian.commit(files=['books.csv'],output=['project.ipynb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
